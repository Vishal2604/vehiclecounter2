{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 6 persons, 13 cars, 1 motorcycle, 2 buss, 5 trucks, 1195.8ms\n",
      "Speed: 19.5ms preprocess, 1195.8ms inference, 19.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 12 cars, 1 motorcycle, 2 buss, 5 trucks, 1844.5ms\n",
      "Speed: 111.6ms preprocess, 1844.5ms inference, 9.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 13 cars, 1 motorcycle, 1 bus, 5 trucks, 1776.1ms\n",
      "Speed: 31.2ms preprocess, 1776.1ms inference, 13.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 13 cars, 1 motorcycle, 4 trucks, 1863.8ms\n",
      "Speed: 36.7ms preprocess, 1863.8ms inference, 11.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 17 cars, 1 motorcycle, 3 trucks, 1582.1ms\n",
      "Speed: 50.7ms preprocess, 1582.1ms inference, 15.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 16 cars, 5 trucks, 2369.0ms\n",
      "Speed: 111.4ms preprocess, 2369.0ms inference, 10.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 13 cars, 1 bus, 4 trucks, 1621.6ms\n",
      "Speed: 26.8ms preprocess, 1621.6ms inference, 21.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 12 cars, 1 motorcycle, 1 bus, 4 trucks, 1287.0ms\n",
      "Speed: 46.2ms preprocess, 1287.0ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 13 cars, 2 motorcycles, 2 buss, 4 trucks, 1689.3ms\n",
      "Speed: 97.6ms preprocess, 1689.3ms inference, 19.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 15 cars, 2 motorcycles, 1 bus, 4 trucks, 1546.8ms\n",
      "Speed: 15.6ms preprocess, 1546.8ms inference, 12.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 16 cars, 4 motorcycles, 4 trucks, 2342.0ms\n",
      "Speed: 33.2ms preprocess, 2342.0ms inference, 15.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 16 cars, 3 motorcycles, 4 trucks, 1257.3ms\n",
      "Speed: 51.2ms preprocess, 1257.3ms inference, 13.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 16 cars, 2 motorcycles, 4 trucks, 1260.5ms\n",
      "Speed: 46.3ms preprocess, 1260.5ms inference, 9.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 15 cars, 1 motorcycle, 1 bus, 3 trucks, 1292.1ms\n",
      "Speed: 19.0ms preprocess, 1292.1ms inference, 26.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 15 cars, 1 motorcycle, 1 bus, 4 trucks, 1297.8ms\n",
      "Speed: 16.0ms preprocess, 1297.8ms inference, 17.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 15 cars, 3 motorcycles, 2 buss, 3 trucks, 1352.8ms\n",
      "Speed: 27.7ms preprocess, 1352.8ms inference, 10.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 10 cars, 2 motorcycles, 2 buss, 3 trucks, 2779.6ms\n",
      "Speed: 23.7ms preprocess, 2779.6ms inference, 7.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 42\u001b[0m\n\u001b[0;32m     38\u001b[0m results \u001b[38;5;241m=\u001b[39m model(img, stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# detections = np.empty((0, 5))\u001b[39;00m\n\u001b[1;32m---> 42\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m results:\n\u001b[0;32m     43\u001b[0m     boxes \u001b[38;5;241m=\u001b[39m r\u001b[38;5;241m.\u001b[39mboxes\n\u001b[0;32m     44\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m box \u001b[38;5;129;01min\u001b[39;00m boxes:\n\u001b[0;32m     45\u001b[0m         \u001b[38;5;66;03m# Bounding Box\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ME\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\utils\\_contextlib.py:36\u001b[0m, in \u001b[0;36m_wrap_generator.<locals>.generator_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;66;03m# Issuing `None` to a generator fires it up\u001b[39;00m\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m---> 36\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[43mgen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m     39\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     40\u001b[0m             \u001b[38;5;66;03m# Forward the response to our caller and get its next request\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ME\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\ultralytics\\engine\\predictor.py:255\u001b[0m, in \u001b[0;36mBasePredictor.stream_inference\u001b[1;34m(self, source, model, *args, **kwargs)\u001b[0m\n\u001b[0;32m    253\u001b[0m \u001b[38;5;66;03m# Inference\u001b[39;00m\n\u001b[0;32m    254\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m profilers[\u001b[38;5;241m1\u001b[39m]:\n\u001b[1;32m--> 255\u001b[0m     preds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minference\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    256\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39membed:\n\u001b[0;32m    257\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m [preds] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(preds, torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;28;01melse\u001b[39;00m preds  \u001b[38;5;66;03m# yield embedding tensors\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ME\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\ultralytics\\engine\\predictor.py:143\u001b[0m, in \u001b[0;36mBasePredictor.inference\u001b[1;34m(self, im, *args, **kwargs)\u001b[0m\n\u001b[0;32m    137\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Runs inference on a given image using the specified model and arguments.\"\"\"\u001b[39;00m\n\u001b[0;32m    138\u001b[0m visualize \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    139\u001b[0m     increment_path(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_dir \u001b[38;5;241m/\u001b[39m Path(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m.\u001b[39mstem, mkdir\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    140\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mvisualize \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msource_type\u001b[38;5;241m.\u001b[39mtensor)\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    142\u001b[0m )\n\u001b[1;32m--> 143\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maugment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maugment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisualize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvisualize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ME\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ME\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ME\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\ultralytics\\nn\\autobackend.py:526\u001b[0m, in \u001b[0;36mAutoBackend.forward\u001b[1;34m(self, im, augment, visualize, embed)\u001b[0m\n\u001b[0;32m    524\u001b[0m \u001b[38;5;66;03m# PyTorch\u001b[39;00m\n\u001b[0;32m    525\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpt \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnn_module:\n\u001b[1;32m--> 526\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maugment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maugment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisualize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvisualize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    528\u001b[0m \u001b[38;5;66;03m# TorchScript\u001b[39;00m\n\u001b[0;32m    529\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjit:\n",
      "File \u001b[1;32mc:\\Users\\ME\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ME\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ME\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\ultralytics\\nn\\tasks.py:112\u001b[0m, in \u001b[0;36mBaseModel.forward\u001b[1;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[0;32m    110\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mdict\u001b[39m):  \u001b[38;5;66;03m# for cases of training and validating while training.\u001b[39;00m\n\u001b[0;32m    111\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss(x, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 112\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ME\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\ultralytics\\nn\\tasks.py:130\u001b[0m, in \u001b[0;36mBaseModel.predict\u001b[1;34m(self, x, profile, visualize, augment, embed)\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m augment:\n\u001b[0;32m    129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predict_augment(x)\n\u001b[1;32m--> 130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predict_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprofile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisualize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ME\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\ultralytics\\nn\\tasks.py:151\u001b[0m, in \u001b[0;36mBaseModel._predict_once\u001b[1;34m(self, x, profile, visualize, embed)\u001b[0m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m profile:\n\u001b[0;32m    150\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_profile_one_layer(m, x, dt)\n\u001b[1;32m--> 151\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# run\u001b[39;00m\n\u001b[0;32m    152\u001b[0m y\u001b[38;5;241m.\u001b[39mappend(x \u001b[38;5;28;01mif\u001b[39;00m m\u001b[38;5;241m.\u001b[39mi \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)  \u001b[38;5;66;03m# save output\u001b[39;00m\n\u001b[0;32m    153\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m visualize:\n",
      "File \u001b[1;32mc:\\Users\\ME\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ME\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ME\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\ultralytics\\nn\\modules\\block.py:238\u001b[0m, in \u001b[0;36mC2f.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    236\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Forward pass through C2f layer.\"\"\"\u001b[39;00m\n\u001b[0;32m    237\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv1(x)\u001b[38;5;241m.\u001b[39mchunk(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m--> 238\u001b[0m \u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mm\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mm\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    239\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv2(torch\u001b[38;5;241m.\u001b[39mcat(y, \u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\ME\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\ultralytics\\nn\\modules\\block.py:238\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    236\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Forward pass through C2f layer.\"\"\"\u001b[39;00m\n\u001b[0;32m    237\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv1(x)\u001b[38;5;241m.\u001b[39mchunk(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m--> 238\u001b[0m y\u001b[38;5;241m.\u001b[39mextend(\u001b[43mm\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mm)\n\u001b[0;32m    239\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv2(torch\u001b[38;5;241m.\u001b[39mcat(y, \u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\ME\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ME\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ME\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\ultralytics\\nn\\modules\\block.py:347\u001b[0m, in \u001b[0;36mBottleneck.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m    346\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Applies the YOLO FPN to input data.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 347\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv2(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv1(x)) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcv2\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ME\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ME\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ME\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\ultralytics\\nn\\modules\\conv.py:54\u001b[0m, in \u001b[0;36mConv.forward_fuse\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward_fuse\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m     53\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Perform transposed convolution of 2D data.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mc:\\Users\\ME\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ME\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ME\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\nn\\modules\\conv.py:458\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    457\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 458\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ME\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\nn\\modules\\conv.py:454\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    450\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[0;32m    452\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[0;32m    453\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[1;32m--> 454\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    455\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import cvzone\n",
    "from math import ceil\n",
    " \n",
    "cap = cv2.VideoCapture(\"C:/Users/ME/Desktop/Trafffic management Govt/vehicle_vids/indiacars.mp4\") \n",
    " \n",
    "model = YOLO(\"Yolo-Weights/yolov8n.pt\")\n",
    " \n",
    "classNames = [\"person\", \"bicycle\", \"car\", \"motorbike\", \"aeroplane\", \"bus\", \"train\", \"truck\", \"boat\",\n",
    "              \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\", \"bird\", \"cat\",\n",
    "              \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\", \"backpack\", \"umbrella\",\n",
    "              \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\", \"sports ball\", \"kite\", \"baseball bat\",\n",
    "              \"baseball glove\", \"skateboard\", \"surfboard\", \"tennis racket\", \"bottle\", \"wine glass\", \"cup\",\n",
    "              \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\", \"apple\", \"sandwich\", \"orange\", \"broccoli\",\n",
    "              \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\", \"chair\", \"sofa\", \"pottedplant\", \"bed\",\n",
    "              \"diningtable\", \"toilet\", \"tvmonitor\", \"laptop\", \"mouse\", \"remote\", \"keyboard\", \"cell phone\",\n",
    "              \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\", \"book\", \"clock\", \"vase\", \"scissors\",\n",
    "              \"teddy bear\", \"hair drier\", \"toothbrush\"\n",
    "              ]\n",
    "\n",
    "while True:\n",
    "    success, img = cap.read()\n",
    "    results = model(img, stream=True) \n",
    "    for r in results:\n",
    "        boxes = r.boxes\n",
    "        for box in boxes:\n",
    "            # Bounding Box\n",
    "            x1, y1, x2, y2 = box.xyxy[0]\n",
    "            x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "            # cv2.rectangle(img,(x1,y1),(x2,y2),(255,0,255),3)\n",
    "            w, h = x2 - x1, y2 - y1\n",
    "            cvzone.cornerRect(img, (x1, y1, w, h), l=10, rt=2)\n",
    "            # Confidence\n",
    "            conf = ceil((box.conf[0] * 100)) / 100\n",
    "            # Class Name\n",
    "            cls = int(box.cls[0])\n",
    "            # currentClass = classNames[cls]\n",
    "            cvzone.putTextRect(img, f'{classNames[cls]} {conf}', (max(0, x1), max(35, y1)), scale=0.6, thickness=1, offset=3)\n",
    "    cv2.imshow(\"Image\", img)\n",
    "    cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All vehicles detection\n",
    "To understand which region is the best to apply mask. This region has the best angle, lighning, etc for detection (do this now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 10 persons, 16 cars, 7 motorcycles, 5 trucks, 458.7ms\n",
      "Speed: 3.0ms preprocess, 458.7ms inference, 27.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 15 cars, 7 motorcycles, 4 trucks, 429.6ms\n",
      "Speed: 3.4ms preprocess, 429.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 15 cars, 7 motorcycles, 4 trucks, 441.6ms\n",
      "Speed: 2.5ms preprocess, 441.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 15 cars, 7 motorcycles, 5 trucks, 452.3ms\n",
      "Speed: 1.9ms preprocess, 452.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 16 cars, 7 motorcycles, 4 trucks, 481.9ms\n",
      "Speed: 2.2ms preprocess, 481.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 16 cars, 7 motorcycles, 4 trucks, 438.6ms\n",
      "Speed: 3.3ms preprocess, 438.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 16 cars, 8 motorcycles, 4 trucks, 464.6ms\n",
      "Speed: 2.7ms preprocess, 464.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 15 cars, 8 motorcycles, 6 trucks, 454.3ms\n",
      "Speed: 1.6ms preprocess, 454.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 17 cars, 6 motorcycles, 1 bus, 7 trucks, 433.8ms\n",
      "Speed: 1.5ms preprocess, 433.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 17 cars, 7 motorcycles, 1 bus, 6 trucks, 436.9ms\n",
      "Speed: 2.1ms preprocess, 436.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 16 cars, 7 motorcycles, 1 bus, 6 trucks, 430.6ms\n",
      "Speed: 1.5ms preprocess, 430.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 12 cars, 7 motorcycles, 1 bus, 7 trucks, 427.9ms\n",
      "Speed: 1.7ms preprocess, 427.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 11 cars, 7 motorcycles, 1 bus, 7 trucks, 439.4ms\n",
      "Speed: 2.4ms preprocess, 439.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 12 cars, 7 motorcycles, 6 trucks, 418.3ms\n",
      "Speed: 1.8ms preprocess, 418.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 13 cars, 8 motorcycles, 5 trucks, 418.5ms\n",
      "Speed: 1.6ms preprocess, 418.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 11 cars, 7 motorcycles, 5 trucks, 415.2ms\n",
      "Speed: 1.7ms preprocess, 415.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 12 cars, 7 motorcycles, 5 trucks, 438.1ms\n",
      "Speed: 1.8ms preprocess, 438.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 15 cars, 7 motorcycles, 5 trucks, 417.8ms\n",
      "Speed: 1.6ms preprocess, 417.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 15 cars, 7 motorcycles, 1 bus, 5 trucks, 417.2ms\n",
      "Speed: 1.6ms preprocess, 417.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 16 cars, 8 motorcycles, 4 trucks, 416.8ms\n",
      "Speed: 1.6ms preprocess, 416.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 15 cars, 8 motorcycles, 1 bus, 4 trucks, 424.6ms\n",
      "Speed: 1.8ms preprocess, 424.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 15 cars, 8 motorcycles, 4 trucks, 424.6ms\n",
      "Speed: 2.0ms preprocess, 424.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 15 cars, 8 motorcycles, 4 trucks, 418.1ms\n",
      "Speed: 1.8ms preprocess, 418.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 16 cars, 9 motorcycles, 4 trucks, 419.3ms\n",
      "Speed: 1.8ms preprocess, 419.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 13 cars, 8 motorcycles, 4 trucks, 414.7ms\n",
      "Speed: 1.6ms preprocess, 414.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 13 cars, 8 motorcycles, 4 trucks, 418.6ms\n",
      "Speed: 1.7ms preprocess, 418.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 14 cars, 8 motorcycles, 5 trucks, 435.2ms\n",
      "Speed: 1.8ms preprocess, 435.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 14 cars, 9 motorcycles, 1 bus, 6 trucks, 446.3ms\n",
      "Speed: 2.8ms preprocess, 446.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 16 cars, 8 motorcycles, 6 trucks, 428.9ms\n",
      "Speed: 1.8ms preprocess, 428.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 15 cars, 8 motorcycles, 5 trucks, 414.7ms\n",
      "Speed: 1.6ms preprocess, 414.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 13 cars, 8 motorcycles, 4 trucks, 438.9ms\n",
      "Speed: 1.7ms preprocess, 438.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 13 cars, 8 motorcycles, 4 trucks, 417.5ms\n",
      "Speed: 1.9ms preprocess, 417.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 14 cars, 8 motorcycles, 4 trucks, 412.3ms\n",
      "Speed: 1.7ms preprocess, 412.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 15 cars, 7 motorcycles, 5 trucks, 418.9ms\n",
      "Speed: 1.6ms preprocess, 418.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 14 cars, 8 motorcycles, 5 trucks, 423.7ms\n",
      "Speed: 1.8ms preprocess, 423.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 15 cars, 7 motorcycles, 4 trucks, 432.6ms\n",
      "Speed: 1.6ms preprocess, 432.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 13 cars, 7 motorcycles, 4 trucks, 448.8ms\n",
      "Speed: 1.8ms preprocess, 448.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 13 cars, 7 motorcycles, 4 trucks, 432.3ms\n",
      "Speed: 1.7ms preprocess, 432.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 15 cars, 7 motorcycles, 4 trucks, 435.5ms\n",
      "Speed: 1.5ms preprocess, 435.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 15 cars, 7 motorcycles, 4 trucks, 425.4ms\n",
      "Speed: 1.9ms preprocess, 425.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 15 cars, 7 motorcycles, 4 trucks, 447.9ms\n",
      "Speed: 1.8ms preprocess, 447.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 15 cars, 7 motorcycles, 4 trucks, 432.6ms\n",
      "Speed: 1.6ms preprocess, 432.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 15 cars, 8 motorcycles, 1 bus, 4 trucks, 426.0ms\n",
      "Speed: 1.8ms preprocess, 426.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 16 cars, 7 motorcycles, 5 trucks, 446.2ms\n",
      "Speed: 2.1ms preprocess, 446.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 15 cars, 7 motorcycles, 5 trucks, 426.3ms\n",
      "Speed: 1.8ms preprocess, 426.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 15 cars, 6 motorcycles, 5 trucks, 419.8ms\n",
      "Speed: 1.7ms preprocess, 419.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 15 cars, 6 motorcycles, 4 trucks, 420.9ms\n",
      "Speed: 1.7ms preprocess, 420.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 18 cars, 6 motorcycles, 4 trucks, 418.6ms\n",
      "Speed: 1.9ms preprocess, 418.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 17 cars, 6 motorcycles, 4 trucks, 418.9ms\n",
      "Speed: 1.6ms preprocess, 418.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 17 cars, 5 motorcycles, 4 trucks, 417.8ms\n",
      "Speed: 1.8ms preprocess, 417.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 13 cars, 7 motorcycles, 4 trucks, 446.2ms\n",
      "Speed: 1.6ms preprocess, 446.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 15 cars, 7 motorcycles, 4 trucks, 415.8ms\n",
      "Speed: 1.6ms preprocess, 415.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 14 cars, 7 motorcycles, 4 trucks, 420.6ms\n",
      "Speed: 1.8ms preprocess, 420.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 13 cars, 6 motorcycles, 4 trucks, 420.4ms\n",
      "Speed: 1.7ms preprocess, 420.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 13 cars, 6 motorcycles, 4 trucks, 425.0ms\n",
      "Speed: 1.5ms preprocess, 425.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 13 cars, 5 motorcycles, 4 trucks, 447.4ms\n",
      "Speed: 1.5ms preprocess, 447.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 14 cars, 5 motorcycles, 4 trucks, 424.5ms\n",
      "Speed: 2.0ms preprocess, 424.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 13 cars, 5 motorcycles, 1 bus, 4 trucks, 420.7ms\n",
      "Speed: 2.9ms preprocess, 420.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 15 cars, 5 motorcycles, 1 bus, 4 trucks, 413.7ms\n",
      "Speed: 2.0ms preprocess, 413.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 15 cars, 5 motorcycles, 4 trucks, 413.7ms\n",
      "Speed: 1.7ms preprocess, 413.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 16 cars, 7 motorcycles, 4 trucks, 414.2ms\n",
      "Speed: 1.4ms preprocess, 414.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 15 cars, 5 motorcycles, 4 trucks, 419.2ms\n",
      "Speed: 1.7ms preprocess, 419.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 15 cars, 6 motorcycles, 4 trucks, 438.9ms\n",
      "Speed: 1.6ms preprocess, 438.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 15 cars, 5 motorcycles, 4 trucks, 419.0ms\n",
      "Speed: 1.8ms preprocess, 419.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 13 cars, 4 motorcycles, 4 trucks, 416.0ms\n",
      "Speed: 1.5ms preprocess, 416.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 15 cars, 5 motorcycles, 5 trucks, 424.2ms\n",
      "Speed: 1.6ms preprocess, 424.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 15 cars, 6 motorcycles, 5 trucks, 421.2ms\n",
      "Speed: 1.5ms preprocess, 421.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 14 cars, 5 motorcycles, 5 trucks, 418.6ms\n",
      "Speed: 1.6ms preprocess, 418.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 13 cars, 5 motorcycles, 6 trucks, 413.5ms\n",
      "Speed: 2.3ms preprocess, 413.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 13 cars, 5 motorcycles, 6 trucks, 415.6ms\n",
      "Speed: 1.8ms preprocess, 415.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 12 cars, 6 motorcycles, 6 trucks, 417.3ms\n",
      "Speed: 1.5ms preprocess, 417.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 13 cars, 5 motorcycles, 5 trucks, 420.2ms\n",
      "Speed: 1.5ms preprocess, 420.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 14 cars, 5 motorcycles, 4 trucks, 420.8ms\n",
      "Speed: 1.7ms preprocess, 420.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 14 cars, 4 motorcycles, 1 bus, 5 trucks, 432.4ms\n",
      "Speed: 1.6ms preprocess, 432.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 12 cars, 6 motorcycles, 1 bus, 4 trucks, 480.5ms\n",
      "Speed: 1.8ms preprocess, 480.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 11 cars, 7 motorcycles, 1 bus, 4 trucks, 428.1ms\n",
      "Speed: 1.9ms preprocess, 428.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 12 cars, 7 motorcycles, 1 bus, 4 trucks, 416.7ms\n",
      "Speed: 2.4ms preprocess, 416.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 12 cars, 7 motorcycles, 4 trucks, 417.1ms\n",
      "Speed: 2.0ms preprocess, 417.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 11 cars, 7 motorcycles, 1 bus, 4 trucks, 417.0ms\n",
      "Speed: 1.9ms preprocess, 417.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 12 cars, 7 motorcycles, 1 bus, 4 trucks, 424.1ms\n",
      "Speed: 1.6ms preprocess, 424.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 12 cars, 6 motorcycles, 4 trucks, 420.0ms\n",
      "Speed: 1.8ms preprocess, 420.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 10 cars, 7 motorcycles, 4 trucks, 413.9ms\n",
      "Speed: 1.7ms preprocess, 413.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 14 cars, 8 motorcycles, 4 trucks, 415.1ms\n",
      "Speed: 2.2ms preprocess, 415.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 13 cars, 7 motorcycles, 4 trucks, 411.1ms\n",
      "Speed: 1.6ms preprocess, 411.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 13 cars, 8 motorcycles, 4 trucks, 442.8ms\n",
      "Speed: 2.3ms preprocess, 442.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 13 cars, 7 motorcycles, 1 bus, 4 trucks, 456.3ms\n",
      "Speed: 1.9ms preprocess, 456.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 13 cars, 7 motorcycles, 5 trucks, 431.4ms\n",
      "Speed: 2.6ms preprocess, 431.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 13 cars, 6 motorcycles, 4 trucks, 416.4ms\n",
      "Speed: 1.6ms preprocess, 416.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 11 cars, 7 motorcycles, 4 trucks, 439.9ms\n",
      "Speed: 1.6ms preprocess, 439.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 12 cars, 6 motorcycles, 6 trucks, 428.2ms\n",
      "Speed: 2.7ms preprocess, 428.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 11 cars, 7 motorcycles, 7 trucks, 436.8ms\n",
      "Speed: 2.4ms preprocess, 436.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 11 cars, 8 motorcycles, 7 trucks, 421.5ms\n",
      "Speed: 3.2ms preprocess, 421.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 9 cars, 9 motorcycles, 6 trucks, 437.1ms\n",
      "Speed: 1.9ms preprocess, 437.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 12 cars, 7 motorcycles, 7 trucks, 431.8ms\n",
      "Speed: 5.1ms preprocess, 431.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 10 cars, 7 motorcycles, 7 trucks, 430.2ms\n",
      "Speed: 1.6ms preprocess, 430.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 9 cars, 7 motorcycles, 7 trucks, 434.1ms\n",
      "Speed: 1.7ms preprocess, 434.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 9 cars, 6 motorcycles, 5 trucks, 449.3ms\n",
      "Speed: 5.1ms preprocess, 449.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 9 cars, 5 motorcycles, 5 trucks, 443.1ms\n",
      "Speed: 1.9ms preprocess, 443.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 10 cars, 7 motorcycles, 5 trucks, 426.1ms\n",
      "Speed: 1.7ms preprocess, 426.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 10 cars, 8 motorcycles, 5 trucks, 436.3ms\n",
      "Speed: 1.7ms preprocess, 436.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 12 cars, 7 motorcycles, 6 trucks, 420.5ms\n",
      "Speed: 1.8ms preprocess, 420.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 10 cars, 7 motorcycles, 7 trucks, 427.7ms\n",
      "Speed: 1.5ms preprocess, 427.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 10 cars, 8 motorcycles, 7 trucks, 455.4ms\n",
      "Speed: 1.6ms preprocess, 455.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 11 cars, 8 motorcycles, 7 trucks, 438.3ms\n",
      "Speed: 2.1ms preprocess, 438.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 10 cars, 7 motorcycles, 6 trucks, 439.6ms\n",
      "Speed: 1.6ms preprocess, 439.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 11 cars, 7 motorcycles, 7 trucks, 467.4ms\n",
      "Speed: 1.8ms preprocess, 467.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 11 cars, 7 motorcycles, 6 trucks, 432.9ms\n",
      "Speed: 2.2ms preprocess, 432.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 11 cars, 8 motorcycles, 5 trucks, 423.6ms\n",
      "Speed: 2.6ms preprocess, 423.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 12 cars, 7 motorcycles, 6 trucks, 427.2ms\n",
      "Speed: 2.6ms preprocess, 427.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 13 cars, 7 motorcycles, 6 trucks, 415.5ms\n",
      "Speed: 1.6ms preprocess, 415.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 12 cars, 8 motorcycles, 6 trucks, 429.1ms\n",
      "Speed: 1.6ms preprocess, 429.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 13 cars, 7 motorcycles, 6 trucks, 423.7ms\n",
      "Speed: 1.7ms preprocess, 423.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 13 cars, 8 motorcycles, 6 trucks, 693.0ms\n",
      "Speed: 2.4ms preprocess, 693.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 13 cars, 7 motorcycles, 6 trucks, 674.5ms\n",
      "Speed: 2.2ms preprocess, 674.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 13 cars, 8 motorcycles, 6 trucks, 682.3ms\n",
      "Speed: 2.7ms preprocess, 682.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 14 cars, 8 motorcycles, 6 trucks, 681.2ms\n",
      "Speed: 2.0ms preprocess, 681.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 13 cars, 8 motorcycles, 6 trucks, 766.1ms\n",
      "Speed: 2.2ms preprocess, 766.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 13 cars, 8 motorcycles, 6 trucks, 683.6ms\n",
      "Speed: 2.2ms preprocess, 683.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 12 cars, 8 motorcycles, 6 trucks, 705.5ms\n",
      "Speed: 2.1ms preprocess, 705.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 11 cars, 9 motorcycles, 6 trucks, 697.8ms\n",
      "Speed: 2.4ms preprocess, 697.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 12 cars, 8 motorcycles, 7 trucks, 764.0ms\n",
      "Speed: 3.8ms preprocess, 764.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 14 cars, 9 motorcycles, 8 trucks, 706.2ms\n",
      "Speed: 2.7ms preprocess, 706.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 12 cars, 7 motorcycles, 7 trucks, 685.6ms\n",
      "Speed: 2.6ms preprocess, 685.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 13 cars, 8 motorcycles, 6 trucks, 735.4ms\n",
      "Speed: 2.4ms preprocess, 735.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 13 cars, 7 motorcycles, 6 trucks, 687.7ms\n",
      "Speed: 2.5ms preprocess, 687.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 13 cars, 8 motorcycles, 5 trucks, 677.2ms\n",
      "Speed: 3.1ms preprocess, 677.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 14 cars, 7 motorcycles, 6 trucks, 732.1ms\n",
      "Speed: 1.9ms preprocess, 732.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 15 cars, 7 motorcycles, 6 trucks, 784.6ms\n",
      "Speed: 3.4ms preprocess, 784.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 13 cars, 6 motorcycles, 6 trucks, 808.4ms\n",
      "Speed: 2.7ms preprocess, 808.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 12 cars, 7 motorcycles, 5 trucks, 1 traffic light, 766.1ms\n",
      "Speed: 2.9ms preprocess, 766.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 13 cars, 6 motorcycles, 4 trucks, 699.2ms\n",
      "Speed: 2.2ms preprocess, 699.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 12 cars, 5 motorcycles, 5 trucks, 699.2ms\n",
      "Speed: 2.4ms preprocess, 699.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 12 cars, 5 motorcycles, 6 trucks, 688.1ms\n",
      "Speed: 2.2ms preprocess, 688.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 10 cars, 5 motorcycles, 5 trucks, 720.3ms\n",
      "Speed: 4.4ms preprocess, 720.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 12 cars, 5 motorcycles, 5 trucks, 695.9ms\n",
      "Speed: 2.2ms preprocess, 695.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 11 cars, 6 motorcycles, 5 trucks, 721.1ms\n",
      "Speed: 2.6ms preprocess, 721.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 12 cars, 4 motorcycles, 5 trucks, 715.0ms\n",
      "Speed: 2.7ms preprocess, 715.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 12 cars, 6 motorcycles, 5 trucks, 725.9ms\n",
      "Speed: 2.6ms preprocess, 725.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 13 cars, 5 motorcycles, 5 trucks, 774.6ms\n",
      "Speed: 3.1ms preprocess, 774.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 14 cars, 5 motorcycles, 5 trucks, 690.9ms\n",
      "Speed: 2.6ms preprocess, 690.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 14 cars, 5 motorcycles, 5 trucks, 684.0ms\n",
      "Speed: 2.2ms preprocess, 684.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 14 cars, 5 motorcycles, 5 trucks, 684.0ms\n",
      "Speed: 2.3ms preprocess, 684.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 13 cars, 6 motorcycles, 5 trucks, 736.9ms\n",
      "Speed: 2.6ms preprocess, 736.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 16 cars, 6 motorcycles, 7 trucks, 711.8ms\n",
      "Speed: 2.5ms preprocess, 711.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 13 cars, 7 motorcycles, 5 trucks, 695.6ms\n",
      "Speed: 2.1ms preprocess, 695.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 11 cars, 6 motorcycles, 5 trucks, 704.0ms\n",
      "Speed: 2.9ms preprocess, 704.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 11 cars, 6 motorcycles, 4 trucks, 685.1ms\n",
      "Speed: 2.8ms preprocess, 685.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 11 cars, 8 motorcycles, 6 trucks, 688.7ms\n",
      "Speed: 2.8ms preprocess, 688.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 15 cars, 7 motorcycles, 4 trucks, 696.4ms\n",
      "Speed: 2.5ms preprocess, 696.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 13 cars, 7 motorcycles, 5 trucks, 691.0ms\n",
      "Speed: 2.3ms preprocess, 691.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 12 cars, 6 motorcycles, 5 trucks, 718.2ms\n",
      "Speed: 2.7ms preprocess, 718.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 11 cars, 6 motorcycles, 6 trucks, 688.9ms\n",
      "Speed: 4.3ms preprocess, 688.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 15 cars, 6 motorcycles, 6 trucks, 707.9ms\n",
      "Speed: 2.3ms preprocess, 707.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 13 cars, 6 motorcycles, 5 trucks, 721.4ms\n",
      "Speed: 2.3ms preprocess, 721.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 13 cars, 4 motorcycles, 5 trucks, 686.4ms\n",
      "Speed: 2.7ms preprocess, 686.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 13 cars, 5 motorcycles, 5 trucks, 691.6ms\n",
      "Speed: 2.1ms preprocess, 691.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 11 cars, 6 motorcycles, 6 trucks, 691.3ms\n",
      "Speed: 2.3ms preprocess, 691.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 12 cars, 7 motorcycles, 6 trucks, 712.1ms\n",
      "Speed: 2.4ms preprocess, 712.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 12 cars, 7 motorcycles, 6 trucks, 690.3ms\n",
      "Speed: 2.6ms preprocess, 690.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 14 cars, 5 motorcycles, 4 trucks, 705.2ms\n",
      "Speed: 2.5ms preprocess, 705.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 13 cars, 5 motorcycles, 4 trucks, 692.8ms\n",
      "Speed: 3.1ms preprocess, 692.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 13 cars, 6 motorcycles, 4 trucks, 723.0ms\n",
      "Speed: 2.2ms preprocess, 723.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 14 cars, 6 motorcycles, 4 trucks, 724.4ms\n",
      "Speed: 2.6ms preprocess, 724.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 14 cars, 6 motorcycles, 4 trucks, 705.7ms\n",
      "Speed: 2.7ms preprocess, 705.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 13 cars, 7 motorcycles, 4 trucks, 732.8ms\n",
      "Speed: 2.0ms preprocess, 732.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 14 cars, 7 motorcycles, 5 trucks, 769.8ms\n",
      "Speed: 2.8ms preprocess, 769.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 13 cars, 6 motorcycles, 4 trucks, 780.4ms\n",
      "Speed: 2.8ms preprocess, 780.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 14 cars, 7 motorcycles, 3 trucks, 698.5ms\n",
      "Speed: 2.5ms preprocess, 698.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 14 cars, 5 motorcycles, 3 trucks, 705.8ms\n",
      "Speed: 2.9ms preprocess, 705.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 14 cars, 3 motorcycles, 4 trucks, 736.7ms\n",
      "Speed: 2.4ms preprocess, 736.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 14 cars, 4 motorcycles, 4 trucks, 724.5ms\n",
      "Speed: 2.9ms preprocess, 724.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 16 cars, 3 motorcycles, 5 trucks, 709.1ms\n",
      "Speed: 2.1ms preprocess, 709.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 14 cars, 3 motorcycles, 4 trucks, 691.6ms\n",
      "Speed: 3.0ms preprocess, 691.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 14 cars, 4 motorcycles, 6 trucks, 737.1ms\n",
      "Speed: 7.2ms preprocess, 737.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 14 cars, 3 motorcycles, 5 trucks, 682.3ms\n",
      "Speed: 2.2ms preprocess, 682.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 13 cars, 3 motorcycles, 6 trucks, 703.0ms\n",
      "Speed: 3.3ms preprocess, 703.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 12 cars, 3 motorcycles, 7 trucks, 704.0ms\n",
      "Speed: 2.2ms preprocess, 704.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 14 cars, 4 motorcycles, 5 trucks, 695.4ms\n",
      "Speed: 2.8ms preprocess, 695.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 13 cars, 4 motorcycles, 3 trucks, 692.7ms\n",
      "Speed: 2.5ms preprocess, 692.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 13 cars, 7 motorcycles, 3 trucks, 688.0ms\n",
      "Speed: 2.2ms preprocess, 688.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 13 cars, 5 motorcycles, 6 trucks, 686.6ms\n",
      "Speed: 2.8ms preprocess, 686.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 12 cars, 4 motorcycles, 6 trucks, 754.2ms\n",
      "Speed: 7.9ms preprocess, 754.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 14 cars, 7 motorcycles, 6 trucks, 706.4ms\n",
      "Speed: 3.1ms preprocess, 706.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 15 cars, 5 motorcycles, 6 trucks, 683.7ms\n",
      "Speed: 3.2ms preprocess, 683.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 15 cars, 5 motorcycles, 5 trucks, 805.5ms\n",
      "Speed: 2.7ms preprocess, 805.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 15 cars, 7 motorcycles, 7 trucks, 707.3ms\n",
      "Speed: 7.0ms preprocess, 707.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 15 cars, 7 motorcycles, 5 trucks, 704.5ms\n",
      "Speed: 2.9ms preprocess, 704.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 15 cars, 7 motorcycles, 5 trucks, 717.9ms\n",
      "Speed: 2.1ms preprocess, 717.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 14 cars, 7 motorcycles, 6 trucks, 731.7ms\n",
      "Speed: 2.9ms preprocess, 731.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 15 cars, 6 motorcycles, 5 trucks, 708.0ms\n",
      "Speed: 3.0ms preprocess, 708.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 14 cars, 6 motorcycles, 6 trucks, 683.4ms\n",
      "Speed: 2.2ms preprocess, 683.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 16 cars, 5 motorcycles, 5 trucks, 773.5ms\n",
      "Speed: 2.2ms preprocess, 773.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 15 cars, 6 motorcycles, 5 trucks, 766.4ms\n",
      "Speed: 2.4ms preprocess, 766.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 15 cars, 5 motorcycles, 4 trucks, 783.1ms\n",
      "Speed: 3.7ms preprocess, 783.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 15 cars, 5 motorcycles, 4 trucks, 713.1ms\n",
      "Speed: 2.3ms preprocess, 713.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 16 cars, 5 motorcycles, 4 trucks, 705.7ms\n",
      "Speed: 2.4ms preprocess, 705.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 16 cars, 4 motorcycles, 4 trucks, 712.3ms\n",
      "Speed: 2.6ms preprocess, 712.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 14 cars, 4 motorcycles, 4 trucks, 723.7ms\n",
      "Speed: 3.1ms preprocess, 723.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 13 cars, 4 motorcycles, 4 trucks, 712.2ms\n",
      "Speed: 2.1ms preprocess, 712.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 13 cars, 4 motorcycles, 4 trucks, 721.4ms\n",
      "Speed: 10.8ms preprocess, 721.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 13 cars, 4 motorcycles, 4 trucks, 699.6ms\n",
      "Speed: 2.5ms preprocess, 699.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 13 cars, 4 motorcycles, 4 trucks, 787.5ms\n",
      "Speed: 3.1ms preprocess, 787.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 14 cars, 4 motorcycles, 3 trucks, 681.3ms\n",
      "Speed: 3.2ms preprocess, 681.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 12 cars, 4 motorcycles, 3 trucks, 682.7ms\n",
      "Speed: 3.3ms preprocess, 682.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 12 cars, 5 motorcycles, 3 trucks, 814.4ms\n",
      "Speed: 2.0ms preprocess, 814.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 13 cars, 6 motorcycles, 3 trucks, 695.5ms\n",
      "Speed: 2.7ms preprocess, 695.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 13 cars, 5 motorcycles, 3 trucks, 753.0ms\n",
      "Speed: 3.3ms preprocess, 753.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 14 cars, 5 motorcycles, 3 trucks, 729.4ms\n",
      "Speed: 2.1ms preprocess, 729.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 15 cars, 6 motorcycles, 3 trucks, 702.5ms\n",
      "Speed: 2.6ms preprocess, 702.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 14 cars, 5 motorcycles, 4 trucks, 696.0ms\n",
      "Speed: 2.2ms preprocess, 696.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 14 cars, 6 motorcycles, 4 trucks, 766.8ms\n",
      "Speed: 2.5ms preprocess, 766.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 12 cars, 6 motorcycles, 4 trucks, 682.0ms\n",
      "Speed: 2.2ms preprocess, 682.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 12 cars, 5 motorcycles, 4 trucks, 692.1ms\n",
      "Speed: 2.5ms preprocess, 692.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 13 cars, 7 motorcycles, 4 trucks, 689.1ms\n",
      "Speed: 2.2ms preprocess, 689.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 14 cars, 5 motorcycles, 5 trucks, 711.0ms\n",
      "Speed: 2.2ms preprocess, 711.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 14 cars, 5 motorcycles, 4 trucks, 691.1ms\n",
      "Speed: 2.6ms preprocess, 691.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 14 cars, 5 motorcycles, 4 trucks, 688.4ms\n",
      "Speed: 2.4ms preprocess, 688.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 15 cars, 4 motorcycles, 4 trucks, 705.3ms\n",
      "Speed: 2.7ms preprocess, 705.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 15 cars, 5 motorcycles, 4 trucks, 705.1ms\n",
      "Speed: 2.4ms preprocess, 705.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 15 cars, 5 motorcycles, 4 trucks, 681.3ms\n",
      "Speed: 2.4ms preprocess, 681.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 15 cars, 6 motorcycles, 4 trucks, 687.3ms\n",
      "Speed: 2.3ms preprocess, 687.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 15 cars, 5 motorcycles, 4 trucks, 685.3ms\n",
      "Speed: 2.3ms preprocess, 685.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 15 cars, 6 motorcycles, 4 trucks, 721.4ms\n",
      "Speed: 2.2ms preprocess, 721.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 15 cars, 4 motorcycles, 4 trucks, 686.9ms\n",
      "Speed: 2.5ms preprocess, 686.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 15 cars, 5 motorcycles, 4 trucks, 707.1ms\n",
      "Speed: 2.1ms preprocess, 707.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 15 cars, 5 motorcycles, 5 trucks, 695.6ms\n",
      "Speed: 2.4ms preprocess, 695.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 15 cars, 6 motorcycles, 5 trucks, 683.6ms\n",
      "Speed: 2.1ms preprocess, 683.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 16 cars, 8 motorcycles, 4 trucks, 687.6ms\n",
      "Speed: 2.1ms preprocess, 687.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 16 cars, 4 motorcycles, 5 trucks, 689.6ms\n",
      "Speed: 2.8ms preprocess, 689.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 15 cars, 6 motorcycles, 5 trucks, 722.8ms\n",
      "Speed: 2.1ms preprocess, 722.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 15 cars, 4 motorcycles, 6 trucks, 689.5ms\n",
      "Speed: 2.2ms preprocess, 689.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 13 cars, 5 motorcycles, 5 trucks, 704.1ms\n",
      "Speed: 2.2ms preprocess, 704.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 13 cars, 3 motorcycles, 5 trucks, 705.5ms\n",
      "Speed: 2.4ms preprocess, 705.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 14 cars, 3 motorcycles, 5 trucks, 689.0ms\n",
      "Speed: 2.8ms preprocess, 689.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 12 cars, 4 motorcycles, 5 trucks, 750.6ms\n",
      "Speed: 2.7ms preprocess, 750.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 11 cars, 5 motorcycles, 6 trucks, 696.4ms\n",
      "Speed: 2.2ms preprocess, 696.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 13 cars, 5 motorcycles, 4 trucks, 711.0ms\n",
      "Speed: 2.2ms preprocess, 711.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 14 cars, 4 motorcycles, 5 trucks, 690.6ms\n",
      "Speed: 2.4ms preprocess, 690.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 13 cars, 5 motorcycles, 5 trucks, 705.8ms\n",
      "Speed: 2.7ms preprocess, 705.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 14 cars, 6 motorcycles, 6 trucks, 790.0ms\n",
      "Speed: 2.4ms preprocess, 790.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 15 cars, 4 motorcycles, 5 trucks, 694.9ms\n",
      "Speed: 2.4ms preprocess, 694.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 14 cars, 4 motorcycles, 4 trucks, 685.3ms\n",
      "Speed: 2.2ms preprocess, 685.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 14 cars, 5 motorcycles, 4 trucks, 707.5ms\n",
      "Speed: 4.1ms preprocess, 707.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 13 cars, 5 motorcycles, 4 trucks, 713.3ms\n",
      "Speed: 3.1ms preprocess, 713.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 14 cars, 4 motorcycles, 4 trucks, 707.3ms\n",
      "Speed: 3.0ms preprocess, 707.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 14 cars, 5 motorcycles, 3 trucks, 723.3ms\n",
      "Speed: 2.5ms preprocess, 723.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 14 cars, 6 motorcycles, 3 trucks, 713.0ms\n",
      "Speed: 2.2ms preprocess, 713.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 14 cars, 5 motorcycles, 4 trucks, 693.2ms\n",
      "Speed: 2.0ms preprocess, 693.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 14 cars, 5 motorcycles, 4 trucks, 738.8ms\n",
      "Speed: 2.8ms preprocess, 738.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 14 cars, 5 motorcycles, 4 trucks, 727.8ms\n",
      "Speed: 2.7ms preprocess, 727.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 14 cars, 4 motorcycles, 3 trucks, 791.3ms\n",
      "Speed: 2.9ms preprocess, 791.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 14 cars, 4 motorcycles, 5 trucks, 734.5ms\n",
      "Speed: 2.8ms preprocess, 734.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 11 cars, 2 motorcycles, 6 trucks, 695.6ms\n",
      "Speed: 2.8ms preprocess, 695.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 12 cars, 4 motorcycles, 6 trucks, 693.4ms\n",
      "Speed: 2.0ms preprocess, 693.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 13 cars, 3 motorcycles, 7 trucks, 685.3ms\n",
      "Speed: 2.4ms preprocess, 685.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 12 cars, 4 motorcycles, 4 trucks, 723.8ms\n",
      "Speed: 2.5ms preprocess, 723.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 13 cars, 2 motorcycles, 4 trucks, 688.7ms\n",
      "Speed: 2.0ms preprocess, 688.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 10 cars, 4 motorcycles, 5 trucks, 715.4ms\n",
      "Speed: 2.4ms preprocess, 715.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 8 cars, 3 motorcycles, 6 trucks, 706.2ms\n",
      "Speed: 3.0ms preprocess, 706.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 10 cars, 6 motorcycles, 6 trucks, 742.2ms\n",
      "Speed: 2.4ms preprocess, 742.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 12 cars, 5 motorcycles, 4 trucks, 688.4ms\n",
      "Speed: 3.2ms preprocess, 688.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 13 cars, 5 motorcycles, 4 trucks, 714.6ms\n",
      "Speed: 2.6ms preprocess, 714.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 14 cars, 5 motorcycles, 3 trucks, 699.9ms\n",
      "Speed: 3.9ms preprocess, 699.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 14 cars, 3 motorcycles, 3 trucks, 702.9ms\n",
      "Speed: 2.6ms preprocess, 702.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 15 cars, 3 motorcycles, 3 trucks, 702.7ms\n",
      "Speed: 2.6ms preprocess, 702.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 15 cars, 4 motorcycles, 3 trucks, 705.1ms\n",
      "Speed: 8.8ms preprocess, 705.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 15 cars, 4 motorcycles, 3 trucks, 736.4ms\n",
      "Speed: 2.3ms preprocess, 736.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 15 cars, 3 motorcycles, 4 trucks, 697.2ms\n",
      "Speed: 3.0ms preprocess, 697.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 13 cars, 4 motorcycles, 5 trucks, 774.5ms\n",
      "Speed: 2.8ms preprocess, 774.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 14 cars, 3 motorcycles, 4 trucks, 857.7ms\n",
      "Speed: 4.0ms preprocess, 857.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import cvzone\n",
    "from math import ceil\n",
    " \n",
    "cap = cv2.VideoCapture(\"C:/Users/Nilesh Singh/OneDrive/Desktop/vids/vidtesting.mp4\")  # For Video\n",
    " \n",
    "model = YOLO(\"Yolo-Weights/yolov8l.pt\")\n",
    " \n",
    "classNames = [\"person\", \"bicycle\", \"car\", \"motorbike\", \"aeroplane\", \"bus\", \"train\", \"truck\", \"boat\",\n",
    "              \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\", \"bird\", \"cat\",\n",
    "              \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\", \"backpack\", \"umbrella\",\n",
    "              \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\", \"sports ball\", \"kite\", \"baseball bat\",\n",
    "              \"baseball glove\", \"skateboard\", \"surfboard\", \"tennis racket\", \"bottle\", \"wine glass\", \"cup\",\n",
    "              \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\", \"apple\", \"sandwich\", \"orange\", \"broccoli\",\n",
    "              \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\", \"chair\", \"sofa\", \"pottedplant\", \"bed\",\n",
    "              \"diningtable\", \"toilet\", \"tvmonitor\", \"laptop\", \"mouse\", \"remote\", \"keyboard\", \"cell phone\",\n",
    "              \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\", \"book\", \"clock\", \"vase\", \"scissors\",\n",
    "              \"teddy bear\", \"hair drier\", \"toothbrush\"\n",
    "              ]\n",
    "while True:\n",
    "    success, img = cap.read()\n",
    "    results = model(img, stream=True)\n",
    " \n",
    "    for r in results:\n",
    "        boxes = r.boxes\n",
    "        for box in boxes:\n",
    "            # Bounding Box\n",
    "            x1, y1, x2, y2 = box.xyxy[0]\n",
    "            x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "            # cv2.rectangle(img,(x1,y1),(x2,y2),(255,0,255),3)\n",
    "            w, h = x2 - x1, y2 - y1\n",
    "            # cvzone.cornerRect(img, (x1, y1, w, h), l=10, rt=2)\n",
    "            # Confidence\n",
    "            conf = ceil((box.conf[0] * 100)) / 100\n",
    "            # Class Name\n",
    "            cls = int(box.cls[0])\n",
    "            currentClass = classNames[cls]\n",
    " \n",
    "            if currentClass == \"car\" or currentClass == \"truck\" or currentClass == \"bus\"  or currentClass == \"motorbike\" and conf > 0.3:\n",
    "                cvzone.putTextRect(img, f'{currentClass} {conf}', (max(0, x1), max(35, y1)),\n",
    "                                   scale=0.6, thickness=1, offset=3)\n",
    "                cvzone.cornerRect(img, (x1, y1, w, h), l=9)\n",
    "    cv2.imshow(\"Image\", img)\n",
    "    cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating mask for all vehicle detection\n",
    "Creating mask for all vehicle detection and only detecting in the particular region (no tracking included)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 4 persons, 4 cars, 6 motorcycles, 446.2ms\n",
      "Speed: 3.0ms preprocess, 446.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 3 cars, 6 motorcycles, 428.9ms\n",
      "Speed: 3.0ms preprocess, 428.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 3 cars, 5 motorcycles, 394.3ms\n",
      "Speed: 2.0ms preprocess, 394.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 3 cars, 5 motorcycles, 388.8ms\n",
      "Speed: 1.7ms preprocess, 388.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 3 cars, 5 motorcycles, 400.0ms\n",
      "Speed: 1.3ms preprocess, 400.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 3 cars, 5 motorcycles, 397.2ms\n",
      "Speed: 1.7ms preprocess, 397.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 3 cars, 6 motorcycles, 394.5ms\n",
      "Speed: 2.0ms preprocess, 394.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 3 cars, 5 motorcycles, 430.9ms\n",
      "Speed: 1.7ms preprocess, 430.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 3 cars, 6 motorcycles, 407.1ms\n",
      "Speed: 1.3ms preprocess, 407.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 3 cars, 5 motorcycles, 396.1ms\n",
      "Speed: 2.6ms preprocess, 396.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 3 cars, 5 motorcycles, 403.4ms\n",
      "Speed: 1.4ms preprocess, 403.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 3 cars, 6 motorcycles, 413.7ms\n",
      "Speed: 2.0ms preprocess, 413.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 3 cars, 5 motorcycles, 411.6ms\n",
      "Speed: 2.0ms preprocess, 411.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 3 cars, 5 motorcycles, 404.3ms\n",
      "Speed: 1.6ms preprocess, 404.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 3 cars, 5 motorcycles, 380.4ms\n",
      "Speed: 1.3ms preprocess, 380.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 3 cars, 5 motorcycles, 383.6ms\n",
      "Speed: 1.8ms preprocess, 383.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 3 cars, 5 motorcycles, 379.7ms\n",
      "Speed: 1.2ms preprocess, 379.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 2 cars, 5 motorcycles, 1 truck, 408.1ms\n",
      "Speed: 1.6ms preprocess, 408.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 2 cars, 5 motorcycles, 1 truck, 432.8ms\n",
      "Speed: 1.7ms preprocess, 432.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 3 cars, 5 motorcycles, 1 truck, 387.8ms\n",
      "Speed: 4.1ms preprocess, 387.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 2 cars, 5 motorcycles, 1 truck, 408.3ms\n",
      "Speed: 1.3ms preprocess, 408.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 2 cars, 5 motorcycles, 1 truck, 426.8ms\n",
      "Speed: 1.3ms preprocess, 426.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 1 car, 5 motorcycles, 1 truck, 384.8ms\n",
      "Speed: 1.3ms preprocess, 384.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 1 car, 5 motorcycles, 1 truck, 386.9ms\n",
      "Speed: 1.2ms preprocess, 386.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 1 car, 4 motorcycles, 1 truck, 384.4ms\n",
      "Speed: 1.3ms preprocess, 384.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 1 car, 4 motorcycles, 1 truck, 393.6ms\n",
      "Speed: 1.3ms preprocess, 393.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 1 car, 4 motorcycles, 1 truck, 395.8ms\n",
      "Speed: 1.2ms preprocess, 395.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 1 car, 4 motorcycles, 1 truck, 394.8ms\n",
      "Speed: 1.7ms preprocess, 394.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 1 car, 4 motorcycles, 1 truck, 385.4ms\n",
      "Speed: 1.3ms preprocess, 385.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 1 car, 4 motorcycles, 1 truck, 406.1ms\n",
      "Speed: 1.2ms preprocess, 406.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 1 car, 4 motorcycles, 1 truck, 383.4ms\n",
      "Speed: 1.3ms preprocess, 383.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 car, 4 motorcycles, 1 truck, 382.5ms\n",
      "Speed: 1.2ms preprocess, 382.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 car, 4 motorcycles, 1 truck, 385.1ms\n",
      "Speed: 1.2ms preprocess, 385.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 4 motorcycles, 1 truck, 384.7ms\n",
      "Speed: 1.2ms preprocess, 384.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 4 motorcycles, 1 truck, 385.0ms\n",
      "Speed: 1.3ms preprocess, 385.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 4 motorcycles, 1 truck, 387.8ms\n",
      "Speed: 1.3ms preprocess, 387.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 4 motorcycles, 1 truck, 390.6ms\n",
      "Speed: 2.0ms preprocess, 390.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 4 motorcycles, 1 truck, 386.2ms\n",
      "Speed: 2.6ms preprocess, 386.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 4 motorcycles, 1 truck, 411.9ms\n",
      "Speed: 3.4ms preprocess, 411.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 4 motorcycles, 1 truck, 387.4ms\n",
      "Speed: 2.3ms preprocess, 387.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 4 motorcycles, 1 truck, 393.9ms\n",
      "Speed: 2.1ms preprocess, 393.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 4 motorcycles, 1 truck, 400.5ms\n",
      "Speed: 2.6ms preprocess, 400.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 4 motorcycles, 1 truck, 390.5ms\n",
      "Speed: 1.4ms preprocess, 390.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 4 motorcycles, 1 truck, 392.1ms\n",
      "Speed: 1.2ms preprocess, 392.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 4 motorcycles, 1 truck, 414.1ms\n",
      "Speed: 1.4ms preprocess, 414.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 4 motorcycles, 1 truck, 385.2ms\n",
      "Speed: 1.3ms preprocess, 385.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 4 motorcycles, 1 truck, 426.4ms\n",
      "Speed: 1.5ms preprocess, 426.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 4 motorcycles, 1 truck, 388.0ms\n",
      "Speed: 1.4ms preprocess, 388.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 4 motorcycles, 1 truck, 385.2ms\n",
      "Speed: 1.3ms preprocess, 385.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 4 motorcycles, 1 truck, 433.3ms\n",
      "Speed: 1.5ms preprocess, 433.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 4 motorcycles, 1 truck, 435.3ms\n",
      "Speed: 1.3ms preprocess, 435.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 car, 4 motorcycles, 1 truck, 390.3ms\n",
      "Speed: 1.7ms preprocess, 390.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 car, 4 motorcycles, 1 truck, 390.7ms\n",
      "Speed: 1.3ms preprocess, 390.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 car, 4 motorcycles, 1 truck, 422.5ms\n",
      "Speed: 1.3ms preprocess, 422.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 car, 4 motorcycles, 1 truck, 390.2ms\n",
      "Speed: 1.3ms preprocess, 390.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 car, 4 motorcycles, 1 truck, 430.2ms\n",
      "Speed: 1.3ms preprocess, 430.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 1 car, 4 motorcycles, 1 truck, 386.2ms\n",
      "Speed: 1.4ms preprocess, 386.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 1 car, 4 motorcycles, 1 truck, 393.5ms\n",
      "Speed: 1.2ms preprocess, 393.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 car, 4 motorcycles, 1 truck, 384.3ms\n",
      "Speed: 1.2ms preprocess, 384.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 1 car, 4 motorcycles, 1 truck, 385.9ms\n",
      "Speed: 1.2ms preprocess, 385.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 1 car, 5 motorcycles, 1 truck, 388.6ms\n",
      "Speed: 1.3ms preprocess, 388.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 1 car, 4 motorcycles, 1 truck, 384.7ms\n",
      "Speed: 1.4ms preprocess, 384.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 1 car, 4 motorcycles, 1 truck, 384.8ms\n",
      "Speed: 1.2ms preprocess, 384.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 1 car, 4 motorcycles, 1 truck, 383.4ms\n",
      "Speed: 1.9ms preprocess, 383.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 car, 4 motorcycles, 1 truck, 390.8ms\n",
      "Speed: 1.2ms preprocess, 390.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 1 car, 4 motorcycles, 1 truck, 390.5ms\n",
      "Speed: 1.6ms preprocess, 390.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 1 car, 5 motorcycles, 1 truck, 399.9ms\n",
      "Speed: 1.6ms preprocess, 399.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 car, 4 motorcycles, 1 truck, 386.7ms\n",
      "Speed: 1.3ms preprocess, 386.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 1 car, 4 motorcycles, 1 truck, 418.0ms\n",
      "Speed: 1.6ms preprocess, 418.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 car, 4 motorcycles, 1 truck, 390.3ms\n",
      "Speed: 1.4ms preprocess, 390.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 car, 4 motorcycles, 1 truck, 393.2ms\n",
      "Speed: 1.4ms preprocess, 393.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 1 car, 4 motorcycles, 1 truck, 387.5ms\n",
      "Speed: 1.3ms preprocess, 387.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 car, 4 motorcycles, 1 truck, 388.3ms\n",
      "Speed: 1.3ms preprocess, 388.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 car, 4 motorcycles, 1 truck, 450.5ms\n",
      "Speed: 1.3ms preprocess, 450.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 car, 4 motorcycles, 1 truck, 470.0ms\n",
      "Speed: 1.7ms preprocess, 470.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 1 car, 4 motorcycles, 1 truck, 425.2ms\n",
      "Speed: 1.7ms preprocess, 425.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 1 car, 4 motorcycles, 1 truck, 426.5ms\n",
      "Speed: 1.9ms preprocess, 426.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 1 car, 4 motorcycles, 1 truck, 448.9ms\n",
      "Speed: 1.6ms preprocess, 448.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 1 car, 4 motorcycles, 1 truck, 421.7ms\n",
      "Speed: 1.9ms preprocess, 421.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 1 car, 4 motorcycles, 1 truck, 422.5ms\n",
      "Speed: 1.6ms preprocess, 422.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 1 car, 4 motorcycles, 1 truck, 440.1ms\n",
      "Speed: 1.9ms preprocess, 440.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 car, 3 motorcycles, 1 truck, 421.4ms\n",
      "Speed: 2.0ms preprocess, 421.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 car, 3 motorcycles, 1 truck, 421.3ms\n",
      "Speed: 2.0ms preprocess, 421.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 1 car, 3 motorcycles, 1 truck, 419.8ms\n",
      "Speed: 1.8ms preprocess, 419.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 1 car, 3 motorcycles, 1 truck, 421.5ms\n",
      "Speed: 1.2ms preprocess, 421.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 1 car, 3 motorcycles, 1 truck, 421.6ms\n",
      "Speed: 1.3ms preprocess, 421.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 car, 3 motorcycles, 1 truck, 417.2ms\n",
      "Speed: 1.5ms preprocess, 417.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 1 car, 3 motorcycles, 1 truck, 418.7ms\n",
      "Speed: 1.7ms preprocess, 418.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 car, 3 motorcycles, 1 truck, 421.0ms\n",
      "Speed: 1.4ms preprocess, 421.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 car, 4 motorcycles, 1 truck, 446.3ms\n",
      "Speed: 1.4ms preprocess, 446.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 car, 3 motorcycles, 1 truck, 427.1ms\n",
      "Speed: 1.4ms preprocess, 427.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 car, 4 motorcycles, 1 truck, 426.2ms\n",
      "Speed: 2.3ms preprocess, 426.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 car, 3 motorcycles, 1 truck, 454.6ms\n",
      "Speed: 1.8ms preprocess, 454.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 1 car, 4 motorcycles, 1 truck, 424.8ms\n",
      "Speed: 1.3ms preprocess, 424.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 car, 4 motorcycles, 1 truck, 413.6ms\n",
      "Speed: 1.4ms preprocess, 413.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 car, 4 motorcycles, 1 truck, 418.7ms\n",
      "Speed: 1.5ms preprocess, 418.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import cvzone\n",
    "from math import ceil\n",
    " \n",
    "cap = cv2.VideoCapture(\"C:/Users/Nilesh Singh/OneDrive/Desktop/vids/vidtesting.mp4\")  # For Video\n",
    " \n",
    "model = YOLO(\"Yolo-Weights/yolov8l.pt\")\n",
    " \n",
    "classNames = [\"person\", \"bicycle\", \"car\", \"motorbike\", \"aeroplane\", \"bus\", \"train\", \"truck\", \"boat\",\n",
    "              \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\", \"bird\", \"cat\",\n",
    "              \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\", \"backpack\", \"umbrella\",\n",
    "              \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\", \"sports ball\", \"kite\", \"baseball bat\",\n",
    "              \"baseball glove\", \"skateboard\", \"surfboard\", \"tennis racket\", \"bottle\", \"wine glass\", \"cup\",\n",
    "              \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\", \"apple\", \"sandwich\", \"orange\", \"broccoli\",\n",
    "              \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\", \"chair\", \"sofa\", \"pottedplant\", \"bed\",\n",
    "              \"diningtable\", \"toilet\", \"tvmonitor\", \"laptop\", \"mouse\", \"remote\", \"keyboard\", \"cell phone\",\n",
    "              \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\", \"book\", \"clock\", \"vase\", \"scissors\",\n",
    "              \"teddy bear\", \"hair drier\", \"toothbrush\"\n",
    "              ]\n",
    "\n",
    "mask = cv2.imread(\"C:/Users/Nilesh Singh/OneDrive/Desktop/vids/vid-mask-1280-720.png\")\n",
    "\n",
    "while True:\n",
    "    success, img = cap.read()\n",
    "    imgRegion = cv2.bitwise_and(img, mask)\n",
    "\n",
    "\n",
    "    # results = model(img, stream=True)\n",
    "    results = model(imgRegion, stream=True)\n",
    " \n",
    "    for r in results:\n",
    "        boxes = r.boxes\n",
    "        for box in boxes:\n",
    "            # Bounding Box\n",
    "            x1, y1, x2, y2 = box.xyxy[0]\n",
    "            x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "            # cv2.rectangle(img,(x1,y1),(x2,y2),(255,0,255),3)\n",
    "            w, h = x2 - x1, y2 - y1\n",
    "            # cvzone.cornerRect(img, (x1, y1, w, h), l=10, rt=2)\n",
    "            # Confidence\n",
    "            conf = ceil((box.conf[0] * 100)) / 100\n",
    "            # Class Name\n",
    "            cls = int(box.cls[0])\n",
    "            currentClass = classNames[cls]\n",
    " \n",
    "            if currentClass == \"car\" or currentClass == \"truck\" or currentClass == \"bus\"  or currentClass == \"motorbike\" and conf > 0.3:\n",
    "                cvzone.putTextRect(img, f'{currentClass} {conf}', (max(0, x1), max(35, y1)),\n",
    "                                   scale=0.6, thickness=1, offset=3)\n",
    "                cvzone.cornerRect(img, (x1, y1, w, h), l=9)\n",
    "    cv2.imshow(\"Image\", img)\n",
    "    # cv2.imshow(\"ImageRegion\", imgRegion)\n",
    "    cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trackeing with limits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# figure out using ChatGpt\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import cvzone\n",
    "import math\n",
    "from sort import Sort\n",
    " \n",
    "cap = cv2.VideoCapture(\"C:/Users/ME/Desktop/Trafffic management Govt/vehicle_vids/cars.mp4\")  # For Video\n",
    " \n",
    "model = YOLO(\"Yolo-Weights/yolov8n.pt\")\n",
    " \n",
    "classNames = [\"person\", \"bicycle\", \"car\", \"motorbike\", \"aeroplane\", \"bus\", \"train\", \"truck\", \"boat\",\n",
    "              \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\", \"bird\", \"cat\",\n",
    "              \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\", \"backpack\", \"umbrella\",\n",
    "              \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\", \"sports ball\", \"kite\", \"baseball bat\",\n",
    "              \"baseball glove\", \"skateboard\", \"surfboard\", \"tennis racket\", \"bottle\", \"wine glass\", \"cup\",\n",
    "              \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\", \"apple\", \"sandwich\", \"orange\", \"broccoli\",\n",
    "              \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\", \"chair\", \"sofa\", \"pottedplant\", \"bed\",\n",
    "              \"diningtable\", \"toilet\", \"tvmonitor\", \"laptop\", \"mouse\", \"remote\", \"keyboard\", \"cell phone\",\n",
    "              \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\", \"book\", \"clock\", \"vase\", \"scissors\",\n",
    "              \"teddy bear\", \"hair drier\", \"toothbrush\"\n",
    "              ]\n",
    " \n",
    "mask = cv2.imread(\"assets/mask-1280-720.png\")\n",
    " \n",
    "# Tracking\n",
    "tracker = Sort(max_age=20, min_hits=3, iou_threshold=0.3)\n",
    "\n",
    "limits = [400, 297, 673, 297]\n",
    "totalCount = []\n",
    " \n",
    "while True:\n",
    "    success, img = cap.read()\n",
    "    imgRegion = cv2.bitwise_and(img, mask)\n",
    " \n",
    "    imgGraphics = cv2.imread(\"assets/graphics.png\", cv2.IMREAD_UNCHANGED)\n",
    "    img = cvzone.overlayPNG(img, imgGraphics, (0, 0))\n",
    "    results = model(imgRegion, stream=True)\n",
    " \n",
    "    detections = np.empty((0, 5))\n",
    " \n",
    "    for r in results:\n",
    "        boxes = r.boxes\n",
    "        for box in boxes:\n",
    "            # Bounding Box\n",
    "            x1, y1, x2, y2 = box.xyxy[0]\n",
    "            x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "            # cv2.rectangle(img,(x1,y1),(x2,y2),(255,0,255),3)\n",
    "            w, h = x2 - x1, y2 - y1\n",
    " \n",
    "            # Confidence\n",
    "            conf = math.ceil((box.conf[0] * 100)) / 100\n",
    "            # Class Name\n",
    "            cls = int(box.cls[0])\n",
    "            currentClass = classNames[cls]\n",
    " \n",
    "            if currentClass == \"car\" or currentClass == \"truck\" or currentClass == \"bus\" \\\n",
    "                    or currentClass == \"motorbike\" and conf > 0.3:\n",
    "                # cvzone.putTextRect(img, f'{currentClass} {conf}', (max(0, x1), max(35, y1)),\n",
    "                #                    scale=0.6, thickness=1, offset=3)\n",
    "                # cvzone.cornerRect(img, (x1, y1, w, h), l=9, rt=5)\n",
    "                currentArray = np.array([x1, y1, x2, y2, conf])\n",
    "                detections = np.vstack((detections, currentArray))\n",
    " \n",
    "    resultsTracker = tracker.update(detections)\n",
    " \n",
    "    cv2.line(img, (limits[0], limits[1]), (limits[2], limits[3]), (0, 0, 255), 5)\n",
    "    for result in resultsTracker:\n",
    "        x1, y1, x2, y2, id = result\n",
    "        x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "        print(result)\n",
    "        w, h = x2 - x1, y2 - y1\n",
    "        cvzone.cornerRect(img, (x1, y1, w, h), l=9, rt=2, colorR=(255, 0, 255))\n",
    "        cvzone.putTextRect(img, f' {int(id)}', (max(0, x1), max(35, y1)),\n",
    "                           scale=2, thickness=3, offset=10)\n",
    " \n",
    "        cx, cy = x1 + w // 2, y1 + h // 2\n",
    "        cv2.circle(img, (cx, cy), 5, (255, 0, 255), cv2.FILLED)\n",
    " \n",
    "        if limits[0] < cx < limits[2] and limits[1] - 15 < cy < limits[1] + 15:\n",
    "            if totalCount.count(id) == 0:\n",
    "                totalCount.append(id)\n",
    "                cv2.line(img, (limits[0], limits[1]), (limits[2], limits[3]), (0, 255, 0), 5)\n",
    " \n",
    "    # cvzone.putTextRect(img, f' Count: {len(totalCount)}', (50, 50))\n",
    "    cv2.putText(img,str(len(totalCount)),(255,100),cv2.FONT_HERSHEY_PLAIN,5,(50,50,255),8)\n",
    " \n",
    "    cv2.imshow(\"Image\", img)\n",
    "    # cv2.imshow(\"ImageRegion\", imgRegion)\n",
    "    cv2.waitKey(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
